{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import nipype.pipeline.engine as pe\r\n",
      "import nipype.interfaces.io as nio\r\n",
      "import nipype.interfaces.fsl as fsl\r\n",
      "import nipype.interfaces.afni as afni\r\n",
      "import nipype.interfaces.utility as util\r\n",
      "from nipype.algorithms import misc\r\n",
      "\r\n",
      "from nipype.workflows.fmri.fsl import create_featreg_preproc\r\n",
      "\r\n",
      "import glob, shutil, re, os\r\n",
      "\r\n",
      "#sids = ['SC2T', 'SPGT']\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "workflow = pe.Workflow(name='preprocess_daphne', base_dir='/home/gdholla1/workflow_folders/')\r\n",
      "\r\n",
      "templates = {'epi':'/home/gdholla1/data/daphne/clean/{subject_id}/run*.nii.gz',}\r\n",
      "            #'FLASH':'/home/gdholla1/data/stop3/masks/structural_2std/{subject_id}/FLASH_magnitude/e20.39.nii.gz'}\r\n",
      "\r\n",
      "subject_ids = [fn.split('/')[-1] for fn in glob.glob('/home/gdholla1/data/daphne/clean/*')]\r\n",
      "\r\n",
      "identity = pe.Node(util.IdentityInterface(fields=['subject_id']), name='identity')\r\n",
      "identity.iterables = [('subject_id', subject_ids)]\r\n",
      "\r\n",
      "selector = pe.Node(nio.SelectFiles(templates), name='selector')\r\n",
      "workflow.connect(identity, 'subject_id', selector, 'subject_id')\r\n",
      "\r\n",
      "\r\n",
      "ds = pe.Node(nio.DataSink(), name='datasink')\r\n",
      "ds.inputs.base_directory = '/home/gdholla1/data/daphne/preprocessed'\r\n",
      "\r\n",
      "# PREPROCESS\r\n",
      "preprocess = create_featreg_preproc()\r\n",
      "#preprocess.get_node('meanfuncmask').iterables = [('frac', [0.1,0.2,0.3])]\r\n",
      "preprocess.get_node('meanfuncmask').inputs.frac = 0.3\r\n",
      "\r\n",
      "TR = 1.2\r\n",
      "preprocess.inputs.inputspec.highpass = 128. / (2 * TR)\r\n",
      "preprocess.get_node('inputspec').iterables = [('fwhm', [0.0, 5.0])]\r\n",
      "#preprocess.get_node('inputspec').iterables = [('fwhm', [5.0])]\r\n",
      "\r\n",
      "workflow.connect(selector, 'epi', preprocess, 'inputspec.func')\r\n",
      "\r\n",
      "\r\n",
      "for k in preprocess.outputs.outputspec.get():\r\n",
      "    workflow.connect(preprocess, 'outputspec.%s' % k, ds, 'feat_preprocess.%s' % k)\r\n",
      "\r\n",
      "def motion_regressors(motion_params, order=0, derivatives=1):\r\n",
      "    \"\"\"Compute motion regressors upto given order and derivative\r\n",
      "\r\n",
      "    motion + d(motion)/dt + d2(motion)/dt2 (linear + quadratic)\r\n",
      "    \"\"\"\r\n",
      "    import os\r\n",
      "    from nipype.utils.filemanip import filename_to_list\r\n",
      "    import numpy as np\r\n",
      "    out_files = []\r\n",
      "    for idx, filename in enumerate(filename_to_list(motion_params)):\r\n",
      "        params = np.genfromtxt(filename)\r\n",
      "        out_params = params\r\n",
      "        for d in range(1, derivatives + 1):\r\n",
      "            cparams = np.vstack((np.repeat(params[0, :][None, :], d, axis=0),\r\n",
      "                                 params))\r\n",
      "            out_params = np.hstack((out_params, np.diff(cparams, d, axis=0)))\r\n",
      "        out_params2 = out_params\r\n",
      "        for i in range(2, order + 1):\r\n",
      "            out_params2 = np.hstack((out_params2, np.power(out_params, i)))\r\n",
      "        filename = os.path.join(os.getcwd(), \"motion_regressor%02d.txt\" % idx)\r\n",
      "        np.savetxt(filename, out_params2, fmt=\"%.10f\")\r\n",
      "        out_files.append(filename)\r\n",
      "    return out_files\r\n",
      "\r\n",
      "\r\n",
      "make_motion_regressors = pe.Node(util.Function(input_names=['motion_params'],\r\n",
      "                                                  output_names=['motion_glm'],\r\n",
      "                                                  function=motion_regressors),\r\n",
      "                                    name='make_motion_regressors')\r\n",
      "\r\n",
      "workflow.connect(preprocess.get_node('realign'), 'par_file', make_motion_regressors, 'motion_params')\r\n",
      "\r\n",
      "filter_out_motion = pe.MapNode(fsl.FilterRegressor(filter_all=True),\r\n",
      "                               iterfield=['in_file','design_file'],\r\n",
      "                               name='filter_out_motion')\r\n",
      "workflow.connect(make_motion_regressors, 'motion_glm', filter_out_motion, 'design_file')\r\n",
      "\r\n",
      "workflow.connect(preprocess.get_node('highpass'), 'out_file', filter_out_motion, 'in_file') \r\n",
      "\r\n",
      "addmean = pe.MapNode(interface=fsl.BinaryMaths(operation='add'),\r\n",
      "                         iterfield=['in_file', 'operand_file'],\r\n",
      "                             name='addmean')\r\n",
      "workflow.connect(filter_out_motion, 'out_file', addmean, 'in_file')\r\n",
      "workflow.connect(preprocess.get_node('meanfunc4'), 'out_file', addmean, 'operand_file')\r\n",
      "\r\n",
      "workflow.connect(addmean, 'out_file', ds, 'motion_regressors_filtered_files')\r\n",
      "\r\n",
      "tsnr = pe.MapNode(misc.TSNR(), iterfield=['in_file'], name='tsnr')\r\n",
      "workflow.connect(preprocess, 'outputspec.highpassed_files', tsnr, 'in_file')\r\n",
      "\r\n",
      "workflow.connect(tsnr, 'mean_file', ds, 'mean_signal')\r\n",
      "workflow.connect(tsnr, 'stddev_file', ds, 'stddev_file')\r\n",
      "workflow.connect(tsnr, 'tsnr_file', ds, 'tsnr_file')\r\n",
      "\r\n",
      "workflow.write_graph()\r\n",
      "workflow.run(plugin='MultiProc', plugin_args={'n_procs':8})\r\n",
      "#workflow.run()\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/gdholla1/projects/daphne/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e896a062eed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m \u001b[0mworkflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MultiProc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'n_procs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m# workflow.run()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gdholla1/git_projects/nipype/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_report'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'write_provenance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gdholla1/git_projects/nipype/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'poll_sleep_duration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remove_node_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtaskid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gdholla1/git_projects/nipype/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[1;34m(notrun)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***********************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[0;32m     94\u001b[0m                             'Check log for details'))\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.interfaces.afni as afni\n",
    "import nipype.interfaces.utility as util\n",
    "from nipype.algorithms import misc\n",
    "\n",
    "from nipype.workflows.fmri.fsl import create_featreg_preproc\n",
    "\n",
    "import glob, shutil, re, os\n",
    "\n",
    "\n",
    "workflow = pe.Workflow(name='preprocess_daphne', base_dir='/home/gdholla1/workflow_folders/')\n",
    "\n",
    "templates = {'cleaned_epi':'/home/gdholla1/data/daphne/preprocess_phys/phys_correction/residuals/_subject_id_{subject_id}/_add_to_residuals*/run*_maths_maths_maths.nii.gz',\n",
    "             'original_epi':'/home/gdholla1/data/daphne/clean/{subject_id}/run*.nii.gz'}\n",
    "            #'FLASH':'/home/gdholla1/data/stop3/masks/structural_2std/{subject_id}/FLASH_magnitude/e20.39.nii.gz'}\n",
    "\n",
    "# subject_ids = [fn.split('/')[-1] for fn in glob.glob('/home/gdholla1/data/daphne/preprocess_phys/phys_correction/residuals//*')]\n",
    "\n",
    "subject_ids = ['S02']\n",
    "\n",
    "identity = pe.Node(util.IdentityInterface(fields=['subject_id']), name='identity')\n",
    "identity.iterables = [('subject_id', subject_ids)]\n",
    "\n",
    "selector = pe.Node(nio.SelectFiles(templates), name='selector')\n",
    "workflow.connect(identity, 'subject_id', selector, 'subject_id')\n",
    "\n",
    "def get_r2(original, residuals):\n",
    "    import nibabel as nb\n",
    "    import os\n",
    "    \n",
    "    image = nb.load(original)\n",
    "    \n",
    "    original = nb.load(original).get_data()\n",
    "    residuals = nb.load(residuals).get_data()\n",
    "    \n",
    "    ss_original = ((original - original.mean(-1)[..., np.newaxis])**2).sum(-1)\n",
    "    ss_residuals = ((residuals - residuals.mean(-1)[..., np.newaxis])**2).sum(-1)\n",
    "\n",
    "    r_2 = (ss_original - ss_residuals) / ss_original\n",
    "    \n",
    "    fn = os.path.abspath('r2.nii.gz')\n",
    "    \n",
    "    nb.save(nb.Nifti1Image(r_2, image.get_affine()), fn)\n",
    "    \n",
    "    return fn\n",
    "\n",
    "r2_node = pe.MapNode(util.Function(function=get_r2,\n",
    "                                input_names=['original', 'residuals'],\n",
    "                                output_names=['r2']),\n",
    "                    iterfield=['original', 'residuals'],\n",
    "                  name='r2_node')\n",
    "\n",
    "\n",
    "workflow.connect(selector, 'cleaned_epi', r2_node, 'residuals')\n",
    "workflow.connect(selector, 'original_epi', r2_node, 'original')\n",
    "\n",
    "\n",
    "ds = pe.Node(nio.DataSink(), name='datasink')\n",
    "\n",
    "ds.inputs.base_directory = '/home/gdholla1/data/daphne/preprocessed_phys'\n",
    "\n",
    "workflow.connect(r2_node, 'r2', ds, 'r2')\n",
    "\n",
    "# PREPROCESS\n",
    "preprocess = create_featreg_preproc()\n",
    "#preprocess.get_node('meanfuncmask').iterables = [('frac', [0.1,0.2,0.3])]\n",
    "preprocess.get_node('meanfuncmask').inputs.frac = 0.3\n",
    "\n",
    "TR = 1.2\n",
    "preprocess.inputs.inputspec.highpass = 128. / (2 * TR)\n",
    "preprocess.get_node('inputspec').iterables = [('fwhm', [0.0, 5.0])]\n",
    "#preprocess.get_node('inputspec').iterables = [('fwhm', [5.0])]\n",
    "\n",
    "workflow.connect(selector, 'cleaned_epi', preprocess, 'inputspec.func')\n",
    "\n",
    "\n",
    "for k in preprocess.outputs.outputspec.get():\n",
    "    workflow.connect(preprocess, 'outputspec.%s' % k, ds, 'feat_preprocess.%s' % k)\n",
    "\n",
    "def motion_regressors(motion_params, order=0, derivatives=1):\n",
    "    \"\"\"Compute motion regressors upto given order and derivative\n",
    "\n",
    "    motion + d(motion)/dt + d2(motion)/dt2 (linear + quadratic)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from nipype.utils.filemanip import filename_to_list\n",
    "    import numpy as np\n",
    "    out_files = []\n",
    "    for idx, filename in enumerate(filename_to_list(motion_params)):\n",
    "        params = np.genfromtxt(filename)\n",
    "        out_params = params\n",
    "        for d in range(1, derivatives + 1):\n",
    "            cparams = np.vstack((np.repeat(params[0, :][None, :], d, axis=0),\n",
    "                                 params))\n",
    "            out_params = np.hstack((out_params, np.diff(cparams, d, axis=0)))\n",
    "        out_params2 = out_params\n",
    "        for i in range(2, order + 1):\n",
    "            out_params2 = np.hstack((out_params2, np.power(out_params, i)))\n",
    "        filename = os.path.join(os.getcwd(), \"motion_regressor%02d.txt\" % idx)\n",
    "        np.savetxt(filename, out_params2, fmt=\"%.10f\")\n",
    "        out_files.append(filename)\n",
    "    return out_files\n",
    "\n",
    "\n",
    "make_motion_regressors = pe.Node(util.Function(input_names=['motion_params'],\n",
    "                                                  output_names=['motion_glm'],\n",
    "                                                  function=motion_regressors),\n",
    "                                    name='make_motion_regressors')\n",
    "\n",
    "workflow.connect(preprocess.get_node('realign'), 'par_file', make_motion_regressors, 'motion_params')\n",
    "\n",
    "filter_out_motion = pe.MapNode(fsl.FilterRegressor(filter_all=True),\n",
    "                               iterfield=['in_file','design_file'],\n",
    "                               name='filter_out_motion')\n",
    "workflow.connect(make_motion_regressors, 'motion_glm', filter_out_motion, 'design_file')\n",
    "\n",
    "workflow.connect(preprocess.get_node('highpass'), 'out_file', filter_out_motion, 'in_file') \n",
    "\n",
    "addmean = pe.MapNode(interface=fsl.BinaryMaths(operation='add'),\n",
    "                         iterfield=['in_file', 'operand_file'],\n",
    "                             name='addmean')\n",
    "workflow.connect(filter_out_motion, 'out_file', addmean, 'in_file')\n",
    "workflow.connect(preprocess.get_node('meanfunc4'), 'out_file', addmean, 'operand_file')\n",
    "\n",
    "workflow.connect(addmean, 'out_file', ds, 'motion_regressors_filtered_files')\n",
    "\n",
    "tsnr = pe.MapNode(misc.TSNR(), iterfield=['in_file'], name='tsnr')\n",
    "workflow.connect(preprocess, 'outputspec.highpassed_files', tsnr, 'in_file')\n",
    "\n",
    "workflow.connect(tsnr, 'mean_file', ds, 'mean_signal')\n",
    "workflow.connect(tsnr, 'stddev_file', ds, 'stddev_file')\n",
    "workflow.connect(tsnr, 'tsnr_file', ds, 'tsnr_file')\n",
    "\n",
    "workflow.write_graph()\n",
    "workflow.run(plugin='MultiProc', plugin_args={'n_procs':4})\n",
    "\n",
    "# workflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gdholla1/notebooks/2016_daphne/r2.nii.gz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_r2('/home/gdholla1/data/daphne/clean/S02/run1.nii.gz', '/home/gdholla1/data/daphne/preprocess_phys/phys_correction/residuals/_subject_id_S02/_add_to_residuals0/run1_maths_maths_maths.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
