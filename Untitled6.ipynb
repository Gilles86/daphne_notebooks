{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import nipype.pipeline.engine as pe\r\n",
      "import nipype.interfaces.io as nio\r\n",
      "import nipype.interfaces.utility as util\r\n",
      "from nipype.workflows.fmri.fsl.estimate import create_modelfit_workflow, create_fixed_effects_flow\r\n",
      "from gilles_workflows import create_fdr_threshold_workflow\r\n",
      "\r\n",
      "meta_workflow = pe.Workflow(name='fit_aron3', base_dir='/home/gdholla1/workflow_folders/')\r\n",
      "\r\n",
      "\r\n",
      "modelfit_workflow = create_modelfit_workflow(name='fit_aron_masked')\r\n",
      "\r\n",
      "modelfit_workflow.base_dir = '/home/gdholla1/workflow_folders/'\r\n",
      "modelfit_workflow.inputs.inputspec.bases = {'dgamma': {'derivs': True}}\r\n",
      "modelfit_workflow.inputs.inputspec.contrasts = [('task', 'T', ['task'], [1.0])]\r\n",
      "modelfit_workflow.inputs.inputspec.film_threshold = 1000\r\n",
      "modelfit_workflow.inputs.inputspec.interscan_interval = 2.0\r\n",
      "modelfit_workflow.inputs.inputspec.model_serial_correlations = True\r\n",
      "\r\n",
      "modelfit_workflow.inputs.inputspec.contrasts = [('stop_failed > go', 'T', ['stop_failed', 'go'], [1.0, -1.0]),\r\n",
      "                                       ('go > stop_failed', 'T', ['go', 'stop_failed'], [1.0, -1.0]),\r\n",
      "                                       ('stop_failed > stop_inhibit', 'T', ['stop_failed', 'stop_inhibit'], [1.0, -1.0]),\r\n",
      "                                       ('stop_inhibit > stop_failed', 'T', ['stop_inhibit', 'stop_failed'], [1.0, -1.0]),\r\n",
      "                                       ('stop_inhibit > go', 'T', ['stop_inhibit', 'go'], [1.0, -1.0]),\r\n",
      "                                       ('go > stop_inhibit', 'T', ['go', 'stop_inhibit'], [1.0, -1.0]),\r\n",
      "                                       ('go > baseline', 'T', ['go'], [1.0]),\r\n",
      "                                       ('stop_inhibit > baseline', 'T', ['stop_inhibit'], [1.0]),\r\n",
      "                                       ('stop_failed > baseline', 'T', ['stop_failed'], [1.0])]\r\n",
      "\r\n",
      "\r\n",
      "identity = pe.Node(util.IdentityInterface(fields=['subject_id', 'run']),\r\n",
      "                                  name='identity')\r\n",
      "\r\n",
      "sids = ['KCAT', 'WSFT', 'WW2T', 'TS6T', 'FMFT', 'HCBT', 'PF5T', 'LV2T', 'UM2T', 'MRCT', 'RSIT', 'KP6T', 'NM3T', 'BI3T', 'SC1T', 'SPGT', 'ZK4T', 'GAIT', 'DA9T', 'VL1T'] \r\n",
      "#sids = sids[-6:]\r\n",
      "print len(sids)\r\n",
      "#sids = ['VL1T', 'GAIT', 'ZK4T', ]\r\n",
      "\r\n",
      "identity.iterables = [('subject_id', sids)]\r\n",
      "identity.inputs.run = [1,2,3]\r\n",
      "\r\n",
      "templates = {'epi':'/home/gdholla1/data/stop3/preprocessed/motion_regressors_filtered_files/_subject_id_{subject_id}/_fwhm_{fwhm}/_addmean*/run*.nii.gz',\r\n",
      "        #'epi':'/home/gdholla1/data/stop3/preprocessed/feat_preprocess/{preprocess}/_subject_id_{subject_id}/_fwhm_{fwhm}/_addmean*/run*.nii.gz',\r\n",
      "                     'mask':'/home/gdholla1/data/stop3/preprocessed/feat_preprocess/mask/_subject_id_{subject_id}/_fwhm_{fwhm}/_dilatemask0/run1*.nii.gz'}\r\n",
      "\r\n",
      "selector = pe.Node(nio.SelectFiles(templates), name='selector')\r\n",
      "#selector.iterables = [('fwhm', [0.0, 1.5, 5.0])]\r\n",
      "selector.iterables = [('fwhm', [5.0])]\r\n",
      "\r\n",
      "def get_session_info(subject_id, run, shift=0):\r\n",
      "    import pandas\r\n",
      "    import numpy as np\r\n",
      "    from nipype.interfaces.base import Bunch\r\n",
      "    \r\n",
      "    df = pandas.read_pickle('/home/gdholla1/data/stop3/behavior/all_data.pandas')\r\n",
      "    \r\n",
      "    df = df[(df.subject_id == subject_id) & (df.run == run)]\r\n",
      "    df['onset'] += shift\r\n",
      "    \r\n",
      "    onsets_task = df['onset'].tolist()\r\n",
      "    onsets_stop_inhibit = df[df.stop & df.succesful_stop]['onset'].tolist()\r\n",
      "    onsets_stop_failed = df[df.stop & (df.succesful_stop == 0)]['onset'].tolist()\r\n",
      "    onsets_go = df[~df.stop]['onset'].tolist()\r\n",
      "\r\n",
      "    info = Bunch(conditions=['go',\r\n",
      "                          'stop_inhibit',\r\n",
      "                          'stop_failed',],\r\n",
      "              onsets=[onsets_go,\r\n",
      "                      onsets_stop_inhibit,\r\n",
      "                      onsets_stop_failed,],\r\n",
      "              durations=[[1]] * 3)\r\n",
      "    \r\n",
      "    return info\r\n",
      "\r\n",
      "\r\n",
      "session_info_getter = pe.MapNode(util.Function(function=get_session_info,\r\n",
      "                                     input_names=['subject_id', 'run', 'shift'],\r\n",
      "                                     output_names=['session_info']),\r\n",
      "                       iterfield=['run'],\r\n",
      "                       name='session_info_getter')\r\n",
      "session_info_getter.iterables = [('shift', [-2.0])]\r\n",
      "\r\n",
      "\r\n",
      "meta_workflow.connect([(identity, selector,\r\n",
      "                   [('subject_id', 'subject_id'),\r\n",
      "                    ('run', 'run')])])\r\n",
      "\r\n",
      "meta_workflow.connect([(identity, session_info_getter,\r\n",
      "                   [('subject_id', 'subject_id'),\r\n",
      "                    ('run', 'run')])])\r\n",
      "\r\n",
      "from nipype.algorithms.modelgen import SpecifyModel\r\n",
      "from nipype.interfaces import fsl\r\n",
      "\r\n",
      "specifymodel = pe.Node(SpecifyModel(), name='specifymodel')\r\n",
      "specifymodel.inputs.input_units = 'secs'\r\n",
      "specifymodel.inputs.time_repetition = 2\r\n",
      "specifymodel.inputs.high_pass_filter_cutoff = 128. / (2. * 2.)\r\n",
      "\r\n",
      "\r\n",
      "meta_workflow.connect([\r\n",
      "                  (selector, modelfit_workflow,\r\n",
      "                   [('epi', 'inputspec.functional_data')]),\r\n",
      "                  (session_info_getter, specifymodel,\r\n",
      "                   [('session_info', 'subject_info'),]),\r\n",
      "                  (selector, specifymodel,\r\n",
      "                  [('epi', 'functional_runs'),]),\r\n",
      "                  (specifymodel, modelfit_workflow,\r\n",
      "                   [('session_info', 'inputspec.session_info'),])\r\n",
      "                  ])\r\n",
      "\r\n",
      "fixedfx = create_fixed_effects_flow()\r\n",
      "\r\n",
      "meta_workflow.connect(selector, 'mask', fixedfx, 'flameo.mask_file')\r\n",
      "\r\n",
      "def num_copes(files):\r\n",
      "    return len(files)\r\n",
      "\r\n",
      "def transpose_copes(copes):    \r\n",
      "    import numpy as np\r\n",
      "    return np.array(copes).T.tolist()\r\n",
      "\r\n",
      "meta_workflow.connect([(modelfit_workflow, fixedfx,\r\n",
      "                   [(('outputspec.copes', transpose_copes), 'inputspec.copes'),\r\n",
      "                    (('outputspec.varcopes', transpose_copes), 'inputspec.varcopes'),\r\n",
      "                    ('outputspec.dof_file', 'inputspec.dof_files'),\r\n",
      "                    (('outputspec.copes', num_copes), 'l2model.num_copes')])])\r\n",
      "\r\n",
      "\r\n",
      "ztopval = pe.MapNode(interface=fsl.ImageMaths(op_string='-ztop',\r\n",
      "                                              suffix='_pval'),\r\n",
      "                     nested=True,\r\n",
      "                     iterfield=['in_file'],\r\n",
      "                     name='ztop',)\r\n",
      "\r\n",
      "fdr_workflow = create_fdr_threshold_workflow()\r\n",
      "\r\n",
      "meta_workflow.connect([\r\n",
      "                  (fixedfx, ztopval,\r\n",
      "                   [('outputspec.zstats', 'in_file'),]),\r\n",
      "                  (fixedfx, fdr_workflow,\r\n",
      "                   [('outputspec.zstats', 'inputspec.z_stats'),]),\r\n",
      "                  (ztopval, fdr_workflow,\r\n",
      "                   [('out_file', 'inputspec.p_values'),]),\r\n",
      "                  (selector, fdr_workflow,\r\n",
      "                   [('mask', 'inputspec.mask'),]),\r\n",
      "                  ])\r\n",
      "\r\n",
      "ds = pe.Node(nio.DataSink(), name='datasink')\r\n",
      "ds.inputs.base_directory = '/home/gdholla1/data/stop3/fit_aron_glm'\r\n",
      "ds.inputs.regexp_substitutions = [('/_flameo([0-9]+)/([a-z0-9_]+).nii.gz', '/\\\\2_contrast\\\\1.nii.gz'),\r\n",
      "        ('/_masker([0-9]+)/zstat1_masked.nii.gz', '/thresholded_zstat_contrast\\\\1.nii.gz'),]\r\n",
      "\r\n",
      "meta_workflow.connect(fixedfx, 'outputspec.zstats', ds, 'zstats')\r\n",
      "meta_workflow.connect(fixedfx, 'outputspec.copes', ds, 'level2_copes')\r\n",
      "meta_workflow.connect(fixedfx, 'outputspec.varcopes', ds, 'level2_varcopes')\r\n",
      "meta_workflow.connect(fixedfx, 'flameo.tdof', ds, 'level2_tdof')\r\n",
      "meta_workflow.connect(fdr_workflow, 'outputspec.thresholded_z_stats', ds, 'thresholded_z_stats')\r\n",
      "\r\n",
      "#meta_workflow.run()\r\n",
      "meta_workflow.run(plugin='MultiProc', plugin_args={'n_procs':7})\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/gdholla1/projects/stop3/fit_aron_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Session</th>\n",
       "      <th>Waitforscanner1c.RTTime</th>\n",
       "      <th>Waitforscanner2c.RTTime</th>\n",
       "      <th>face3sec.OnsetTime</th>\n",
       "      <th>syncvalue[SubTrial]</th>\n",
       "      <th>subject</th>\n",
       "      <th>onset</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90004</td>\n",
       "      <td>164401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90004</td>\n",
       "      <td>164401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90004</td>\n",
       "      <td>164401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90004</td>\n",
       "      <td>164401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90004</td>\n",
       "      <td>164401</td>\n",
       "      <td>176077</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.073</td>\n",
       "      <td>1</td>\n",
       "      <td>cs-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  Session  Waitforscanner1c.RTTime  Waitforscanner2c.RTTime  \\\n",
       "0       1        2                    90004                   164401   \n",
       "1       1        2                    90004                   164401   \n",
       "2       1        2                    90004                   164401   \n",
       "3       1        2                    90004                   164401   \n",
       "4       1        2                    90004                   164401   \n",
       "\n",
       "   face3sec.OnsetTime  syncvalue[SubTrial]  subject   onset  subject_id  \\\n",
       "0                 NaN                  NaN      NaN     NaN           1   \n",
       "1                 NaN                  NaN      NaN     NaN           1   \n",
       "2                 NaN                  NaN      NaN     NaN           1   \n",
       "3                 NaN                  NaN      NaN     NaN           1   \n",
       "4              176077                   12      NaN  86.073           1   \n",
       "\n",
       "  condition  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       cs-  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_pickle('/home/gdholla1/data/daphne/behavior/all_data.pandas')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_session_info(subject_id, run=1, shift=0):\n",
    "    import pandas\n",
    "    import numpy as np\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    \n",
    "    if (type(subject_id) == str) and  subject_id.startswith('S'):\n",
    "        subject_id = int(subject_id[1:])\n",
    "    \n",
    "    if run == 1:\n",
    "        df = pandas.read_pickle('/home/gdholla1/data/daphne/behavior/all_data.pandas')\n",
    "    elif run == 2:\n",
    "        df = pandas.read_pickle('/home/gdholla1/data/daphne/behavior/all_data2.pandas')\n",
    "    \n",
    "    df = df[(df.subject_id == subject_id)]\n",
    "    df['onset'] += shift\n",
    "    \n",
    "    onsets_csp = df[df.condition == 'cs+']['onset'].tolist()\n",
    "    onsets_csm = df[df.condition == 'cs-']['onset'].tolist()\n",
    "    onsets_shock = df[df.condition == 'shock']['onset'].tolist()\n",
    "\n",
    "    info = Bunch(conditions=['cs+',\n",
    "                          'cs-',\n",
    "                          'shock',],\n",
    "              onsets=[onsets_csp,\n",
    "                      onsets_csm,\n",
    "                      onsets_shock,],\n",
    "              durations=[[3]] * 3)\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x86b4810>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.interfaces.utility as util\n",
    "from nipype.workflows.fmri.fsl.estimate import create_modelfit_workflow, create_fixed_effects_flow\n",
    "from gilles_workflows import create_fdr_threshold_workflow\n",
    "\n",
    "meta_workflow = pe.Workflow(name='fit_daphne', base_dir='/home/gdholla1/workflow_folders/')\n",
    "\n",
    "\n",
    "modelfit_workflow = create_modelfit_workflow(name='fit_daphne_modelfit')\n",
    "\n",
    "modelfit_workflow.base_dir = '/home/gdholla1/workflow_folders/'\n",
    "modelfit_workflow.inputs.inputspec.bases = {'dgamma': {'derivs': True}}\n",
    "modelfit_workflow.inputs.inputspec.film_threshold = 1000\n",
    "modelfit_workflow.inputs.inputspec.interscan_interval = 1.2\n",
    "modelfit_workflow.inputs.inputspec.model_serial_correlations = True\n",
    "\n",
    "modelfit_workflow.inputs.inputspec.contrasts = [('cs+ > baseline', 'T', ['cs+'], [1.0]),\n",
    "                                                ('cs- > baseline', 'T', ['cs-'], [1.0]),\n",
    "                                                ('shock > baseline', 'T', ['shock'], [1.0]),\n",
    "                                                ('cs+ > cs-', 'T', ['cs+', 'cs-'], [1.0, -1.0]),                                                \n",
    "                                                ('shock > cs+', 'T', ['shock', 'cs+'], [1.0, -1.0]),                                                                                                \n",
    "                                                ('shock > cs-', 'T', ['shock', 'cs-'], [1.0, -1.0]),                                                                                                                                                \n",
    "                                                ('task > baseline', 'T', ['cs+', 'cs-', 'shock'], [1.0, 1.0, 1.0]),]\n",
    "\n",
    "\n",
    "identity = pe.Node(util.IdentityInterface(fields=['subject_id', 'run']),\n",
    "                                  name='identity')\n",
    "\n",
    "sids = ['S00']\n",
    "identity.iterables = [('subject_id', sids)]\n",
    "identity.inputs.run = [1]\n",
    "\n",
    "templates = {'epi':'/home/gdholla1/data/daphne/preprocess_phys/motion_regressors_filtered_files/_subject_id_{subject_id}/_fwhm_{fwhm}/_addmean*/run{run}_maths_maths_maths_dtype_mcf_mask_gms_tempfilt_regfilt_maths.nii.gz',\n",
    "                     'mask':'/home/gdholla1/data/daphne/preprocess_phys/feat_preprocess/mask/_subject_id_{subject_id}/_fwhm_{fwhm}/_dilatemask0/run1_maths_maths_maths_dtype_mcf_bet_thresh_dil.nii.gz'}\n",
    "\n",
    "selector = pe.Node(nio.SelectFiles(templates), name='selector')\n",
    "#selector.iterables = [('fwhm', [0.0, 1.5, 5.0])]\n",
    "selector.iterables = [('fwhm', [0.0])]\n",
    "\n",
    "def get_session_info(subject_id, run=1, shift=0):\n",
    "    import pandas\n",
    "    import numpy as np\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    \n",
    "    if (type(subject_id) == str) and  subject_id.startswith('S'):\n",
    "        subject_id = int(subject_id[1:])\n",
    "    \n",
    "    if run == 1:\n",
    "        df = pandas.read_pickle('/home/gdholla1/data/daphne/behavior/all_data.pandas')\n",
    "    elif run == 2:\n",
    "        df = pandas.read_pickle('/home/gdholla1/data/daphne/behavior/all_data2.pandas')\n",
    "    \n",
    "    df = df[(df.subject_id == subject_id)]\n",
    "    df['onset'] += shift\n",
    "    \n",
    "    onsets_csp = df[df.condition == 'cs+']['onset'].tolist()\n",
    "    onsets_csm = df[df.condition == 'cs-']['onset'].tolist()\n",
    "    onsets_shock = df[df.condition == 'shock']['onset'].tolist()\n",
    "\n",
    "    info = Bunch(conditions=['cs+',\n",
    "                          'cs-',\n",
    "                          'shock',],\n",
    "              onsets=[onsets_csp,\n",
    "                      onsets_csm,\n",
    "                      onsets_shock,],\n",
    "              durations=[[3]] * 3)\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "session_info_getter = pe.MapNode(util.Function(function=get_session_info,\n",
    "                                     input_names=['subject_id', 'run', 'shift'],\n",
    "                                     output_names=['session_info']),\n",
    "                       iterfield=['run'],\n",
    "                       name='session_info_getter')\n",
    "session_info_getter.iterables = [('shift', [0.0])]\n",
    "\n",
    "\n",
    "meta_workflow.connect([(identity, selector,\n",
    "                   [('subject_id', 'subject_id'),\n",
    "                    ('run', 'run')])])\n",
    "\n",
    "meta_workflow.connect([(identity, session_info_getter,\n",
    "                   [('subject_id', 'subject_id'),\n",
    "                    ('run', 'run')])])\n",
    "\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces import fsl\n",
    "\n",
    "specifymodel = pe.Node(SpecifyModel(), name='specifymodel')\n",
    "specifymodel.inputs.input_units = 'secs'\n",
    "specifymodel.inputs.time_repetition = 2\n",
    "specifymodel.inputs.high_pass_filter_cutoff = 128. / (2. * 2.)\n",
    "\n",
    "\n",
    "meta_workflow.connect([\n",
    "                  (selector, modelfit_workflow,\n",
    "                   [('epi', 'inputspec.functional_data')]),\n",
    "                  (session_info_getter, specifymodel,\n",
    "                   [('session_info', 'subject_info'),]),\n",
    "                  (selector, specifymodel,\n",
    "                  [('epi', 'functional_runs'),]),\n",
    "                  (specifymodel, modelfit_workflow,\n",
    "                   [('session_info', 'inputspec.session_info'),])\n",
    "                  ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ztopval = pe.MapNode(interface=fsl.ImageMaths(op_string='-ztop',\n",
    "                                              suffix='_pval'),\n",
    "                     nested=True,\n",
    "                     iterfield=['in_file'],\n",
    "                     name='ztop',)\n",
    "\n",
    "fdr_workflow = create_fdr_threshold_workflow()\n",
    "\n",
    "def pickfirst(x):\n",
    "    return x[0]\n",
    "\n",
    "meta_workflow.connect([(modelfit_workflow, fdr_workflow,\n",
    "                   [(('outputspec.zfiles', pickfirst), 'inputspec.z_stats'),\n",
    "                    (('outputspec.pfiles', pickfirst), 'inputspec.p_values'),])])\n",
    "\n",
    "meta_workflow.connect(selector, 'mask', fdr_workflow, 'inputspec.mask')\n",
    "                       \n",
    "\n",
    "ds = pe.Node(nio.DataSink(), name='datasink')\n",
    "ds.inputs.base_directory = '/home/gdholla1/data/daphne/fit_glm'\n",
    "ds.inputs.regexp_substitutions = [('/_flameo([0-9]+)/([a-z0-9_]+).nii.gz', '/\\\\2_contrast\\\\1.nii.gz'),\n",
    "        ('/_masker([0-9]+)/zstat1_masked.nii.gz', '/thresholded_zstat_contrast\\\\1.nii.gz'),]\n",
    "\n",
    "\n",
    "meta_workflow.connect(fdr_workflow, 'outputspec.thresholded_z_stats', ds, 'thresholded_z_stats')\n",
    "\n",
    "meta_workflow.connect([(modelfit_workflow, ds,\n",
    "                   [('outputspec.copes', 'copes'),\n",
    "                    ('outputspec.varcopes', 'varcopes'),\n",
    "                    ('outputspec.dof_file', 'dof_files'),\n",
    "                    ('outputspec.zfiles', 'zstats'),])])\n",
    "\n",
    "meta_workflow.run()\n",
    "# meta_workflow.run(plugin='MultiProc', plugin_args={'n_procs':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
